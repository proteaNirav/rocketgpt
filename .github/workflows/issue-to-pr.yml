name: Issue → AI Code PR (Formulator → OpenAI)

on:
  issue_comment:
    types: [created]

permissions:
  contents: write
  pull-requests: write
  issues: read

jobs:
  generate:
    if: startsWith(github.event.comment.body, '/codegen')
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      REPO: ${{ github.repository }}
      ISSUE_NUMBER: ${{ github.event.issue.number }}
      RUN_ID: ${{ github.run_id }}
      COOLDOWN_MIN: "10"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---- Guardrails: actor permission + label gate ----
      - name: Enforce actor permissions & label
        uses: actions/github-script@v7
        with:
          script: |
            const core = require('@actions/core');
            const {context, github} = require('@actions/github');
            const actor = context.actor;
            const repo = context.repo;
            const issue_number = context.payload.issue.number;

            const perm = await github.rest.repos.getCollaboratorPermissionLevel({
              owner: repo.owner, repo: repo.repo, username: actor
            });
            const allowed = ['admin','maintain','write'].includes(perm.data.permission);
            if (!allowed) core.setFailed(`User ${actor} is not allowed to run /codegen`);

            const {data: labels} = await github.rest.issues.listLabelsOnIssue({
              owner: repo.owner, repo: repo.repo, issue_number
            });
            if (!labels.find(l => l.name === 'approved-for-codegen')) {
              core.setFailed('Missing required label: approved-for-codegen');
            }

      - name: Cooldown check (simple rate limit)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ts=$(date +%s)
          last=$(gh issue view $ISSUE_NUMBER --json comments --jq '.comments[]?|select(.body|startswith("[codegen-run]"))|.createdAt' | tail -n1)
          if [ -n "$last" ]; then
            last_ts=$(date -d "$last" +%s)
            diff=$(( (ts - last_ts)/60 ))
            if [ "$diff" -lt "$COOLDOWN_MIN" ]; then
              echo "Too soon since last run ($diff min)."; exit 1
            fi
          fi
          gh issue comment $ISSUE_NUMBER -b "[codegen-run] $(date -u +%FT%TZ)"

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install deps
        run: |
          npm init -y >/dev/null 2>&1 || true
          npm i @octokit/rest js-yaml glob
          # install your formulator (adjust name if different)
          npm i -D @protea/prompt-formulator

      - name: Add codegen scripts
        run: |
          mkdir -p tools
          cat > tools/formulator-adapter.mjs <<'EOF'
          import fs from "fs";
          import path from "path";

          async function loadFormulator() {
            const candidates = [
              "@protea/prompt-formulator",
              "prompt-formulator",
              "npm-prompt-formulator",
            ];
            for (const name of candidates) {
              try { return await import(name); } catch {}
            }
            throw new Error("Prompt Formulator package not found.");
          }

          export async function makeSpecFromThread(thread) {
            const formulator = await loadFormulator();
            const fn = formulator.formatSpec || formulator.generate || formulator.transform;
            if (typeof fn !== "function") throw new Error("Formulator lacks formatSpec/generate/transform");

            const spec = await fn(thread, {
              style: "rocketgpt",
              sectionOrder: ["title","context","targets","db","api","ui","acceptance","notes"],
            });

            const outDir = path.join(process.cwd(), "specs", ".generated");
            fs.mkdirSync(outDir, { recursive: true });
            fs.writeFileSync(path.join(outDir, "last-spec.md"), spec, "utf8");
            return spec;
          }
          EOF

          cat > tools-issue-codegen.mjs <<'EOF'
          import fs from 'fs';
          import path from 'path';
          import { Octokit } from '@octokit/rest';
          import { makeSpecFromThread } from './tools/formulator-adapter.mjs';

          const openaiKey = process.env.OPENAI_API_KEY;
          const token = process.env.GITHUB_TOKEN;
          const [owner, repo] = process.env.REPO.split('/');
          const issueNumber = Number(process.env.ISSUE_NUMBER);

          if (!openaiKey) { console.error('OPENAI_API_KEY missing'); process.exit(1); }
          const octokit = new Octokit({ auth: token });

          async function fetchIssueThread() {
            const issue = await octokit.issues.get({ owner, repo, issue_number: issueNumber });
            const comments = await octokit.issues.listComments({ owner, repo, issue_number: issueNumber, per_page: 100 });
            const thread = [
              `# Title: ${issue.data.title}`,
              `# Body:\n${issue.data.body || ''}`,
              ...comments.data.map(c => `\n## Comment by @${c.user.login} at ${c.created_at}\n${c.body}`)
            ].join('\n')
            .replace(/(api|secret|key|token|password)\s*[:=]\s*[^\s]+/gi, '$1: [REDACTED]')
            .slice(0, 50000);
            return thread;
          }

          function makeOpenAIPrompt(spec) {
            return `
You are a senior full-stack engineer for RocketGPT (Next.js 14 App Router + Supabase Edge Functions).
Given this SPEC, output ONLY file blocks.

SPEC:
${spec}

Constraints:
- TypeScript everywhere.
- Respect existing structure; create files if missing.
- Keep edits focused on the spec.
- If DB changes are required, create a single SQL migration at "supabase/migrations/<timestamp>_auto.sql".
- Ensure Node 20 + Next 14 compatibility.
- Edge Functions: Supabase Deno style.
- Next: App Router (no pages/ directory).

OUTPUT FORMAT (strict):
\`\`\`file:<relative-path-from-repo-root>
<entire file contents>
\`\`\`
`;
          }

          async function callOpenAI(prompt) {
            const res = await fetch('https://api.openai.com/v1/chat/completions', {
              method: 'POST',
              headers: { 'Authorization': `Bearer ${openaiKey}`, 'Content-Type': 'application/json' },
              body: JSON.stringify({
                model: 'gpt-4o-mini',
                temperature: 0.2,
                max_tokens: 4000,
                messages: [{ role: 'user', content: prompt }]
              })
            });
            if (!res.ok) {
              const t = await res.text();
              throw new Error(`OpenAI error ${res.status}: ${t}`);
            }
            const j = await res.json();
            return j.choices?.[0]?.message?.content || '';
          }

          function allowedPath(rel) {
            const ALLOW = [
              /^supabase\/functions\//,
              /^supabase\/migrations\//,
              /^rocketgpt_v3_full\/webapp\/next\//,
              /^app\//, /^lib\//, /^components\//,
            ];
            return ALLOW.some(r => r.test(rel)) && !rel.includes('..');
          }

          function applyFiles(markup) {
            const re = /```file:([^\n]+)\n([\s\S]*?)```/g;
            let m, count = 0, blocked = [];
            while ((m = re.exec(markup)) !== null) {
              const rel = m[1].trim();
              const content = m[2];

              if (!/\.([tj]sx?|sql|md|ya?ml|json|css|svg)$/.test(rel)) { blocked.push(rel); continue; }
              if (Buffer.byteLength(content, 'utf8') > 500*1024) { blocked.push(rel); continue; }
              if (!allowedPath(rel)) { blocked.push(rel); continue; }

              const target = path.join(process.cwd(), rel);
              fs.mkdirSync(path.dirname(target), { recursive: true });
              fs.writeFileSync(target, content, 'utf8');
              console.log('Wrote', rel);
              count++;
            }
            if (blocked.length) console.warn('Blocked paths/files:', blocked);
            if (count === 0) { console.error('No acceptable file blocks produced.'); process.exit(2); }
          }

          (async () => {
            const thread = await fetchIssueThread();
            const spec = await makeSpecFromThread(thread);     // Formulator → spec
            const prompt = makeOpenAIPrompt(spec);
            const out = await callOpenAI(prompt);
            applyFiles(out);
          })().catch(e => { console.error(e); process.exit(1); });
          EOF

      - name: Run codegen (Formulator → OpenAI)
        run: node tools-issue-codegen.mjs

      # ---- Quality checks → Draft PR if any fail ----
      - name: Lint
        id: lint
        run: npx eslint . --ext .ts,.tsx || echo "status=fail" >> $GITHUB_OUTPUT
        working-directory: rocketgpt_v3_full/webapp/next

      - name: Typecheck
        id: tsc
        run: npx tsc --noEmit || echo "status=fail" >> $GITHUB_OUTPUT
        working-directory: rocketgpt_v3_full/webapp/next

      - name: Build
        id: build
        run: npm run build || echo "status=fail" >> $GITHUB_OUTPUT
        working-directory: rocketgpt_v3_full/webapp/next

      - name: Create PR (draft if checks failed)
        uses: peter-evans/create-pull-request@v6
        with:
          title: "AI Codegen PR from Issue #${{ env.ISSUE_NUMBER }}"
          body: "Generated from `/codegen` on issue #${{ env.ISSUE_NUMBER }} (Formulator → OpenAI)."
          commit-message: "chore(ai): apply code from issue discussion"
          branch: "ai/from-issue-${{ env.ISSUE_NUMBER }}-${{ env.RUN_ID }}"
          labels: "ai-codegen, automated"
          draft: ${{ steps.lint.outputs.status == 'fail' || steps.tsc.outputs.status == 'fail' || steps.build.outputs.status == 'fail' }}
