import { NextRequest, NextResponse } from "next/server";
import { createClient, type SupabaseClient } from "@supabase/supabase-js";
import OpenAI from "openai";

import {
  getNextPendingBuilderStep,
  markBuilderStepRunning,
  markBuilderStepSuccess,
  markBuilderStepFailed
} from "@/lib/orchestrator/builder_executor";

export const dynamic = "force-dynamic";

// -----------------------------------------------
// Supabase Admin Client
// -----------------------------------------------

function getSupabaseAdminClient(): SupabaseClient {
  const url =
    process.env.SUPABASE_URL ?? process.env.NEXT_PUBLIC_SUPABASE_URL;
  const serviceKey =
    process.env.SUPABASE_SERVICE_ROLE_KEY ??
    process.env.SUPABASE_SERVICE_KEY ??
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

  if (!url || !serviceKey) {
    throw new Error(
      "Supabase admin client is not configured. " +
        "Ensure SUPABASE_URL or NEXT_PUBLIC_SUPABASE_URL " +
        "and SUPABASE_SERVICE_ROLE_KEY or SUPABASE_SERVICE_KEY (or anon key in dev) are set."
    );
  }

  return createClient(url, serviceKey, {
    auth: {
      persistSession: false
    }
  });
}

// -----------------------------------------------
// OpenAI Client for Builder
// -----------------------------------------------

function getOpenAIClient() {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error(
      "OPENAI_API_KEY is not set. Builder execution requires OpenAI API key."
    );
  }
  return new OpenAI({ apiKey });
}

// -----------------------------------------------
// POST /api/orchestrator/builder/execute-all
// -----------------------------------------------
//
// Body: { runId: number, model?: string, maxSteps?: number }
//
// Executes pending builder steps for this runId sequentially,
// up to maxSteps (default 10).
// -----------------------------------------------

export async function POST(req: NextRequest) {
  const startedAt = Date.now();

  try {
    const body = await req.json();
    const { runId, model, maxSteps } = body as {
      runId: number;
      model?: string;
      maxSteps?: number;
    };

    if (typeof runId !== "number" || !Number.isFinite(runId)) {
      return NextResponse.json(
        {
          error: "InvalidPayload",
          message: "runId must be a finite number."
        },
        { status: 400 }
      );
    }

    const limit =
      typeof maxSteps === "number" && maxSteps > 0 ? maxSteps : 10;

    const supabase = getSupabaseAdminClient();
    const openai = getOpenAIClient();

    const usedModel = model ?? process.env.RGPT_BUILDER_MODEL ?? "gpt-4.1-mini";

    const executions: any[] = [];
    let executedCount = 0;

    while (executedCount < limit) {
      const nextStep = await getNextPendingBuilderStep(supabase, runId);

      if (!nextStep) {
        break; // no more pending steps
      }

      const stepStart = Date.now();
      let status: "success" | "failed" = "success";
      let finalStepRow: any;
      let errorMessage: string | null = null;

      // Mark as running
      const runningStep = await markBuilderStepRunning(
        supabase,
        nextStep.id
      );

      const messages = [
        {
          role: "system",
          content:
            "You are the Builder agent for RocketGPT. " +
            "You generate precise, deterministic code modifications and explanations for the RocketGPT codebase. " +
            "Keep output concise, use code blocks, and avoid extra commentary."
        },
        {
          role: "user",
          content: runningStep.instruction
        }
      ] as const;

      const llmInput = JSON.stringify(
        {
          model: usedModel,
          messages
        },
        null,
        2
      );

      let llmOutput = "";

      try {
        const completion = await openai.chat.completions.create({
          model: usedModel,
          messages: messages as any,
          temperature: 0.2
        });

        llmOutput =
          completion.choices?.[0]?.message?.content ?? "";
        finalStepRow = await markBuilderStepSuccess(
          supabase,
          runningStep.id,
          llmInput,
          llmOutput
        );
      } catch (innerErr: any) {
        status = "failed";
        errorMessage = innerErr?.message ?? "OpenAI call failed.";
        finalStepRow = await markBuilderStepFailed(
          supabase,
          runningStep.id,
          errorMessage,
          llmInput
        );
      }

      const stepDurationMs = Date.now() - stepStart;

      executions.push({
        stepId: finalStepRow.id,
        planner_step_no: finalStepRow.planner_step_no,
        builder_step_no: finalStepRow.builder_step_no,
        status,
        errorMessage,
        durationMs: stepDurationMs
      });

      executedCount += 1;
    }

    // Count remaining pending steps
    const { count: remainingPending } = await supabase
      .from("rgpt_builder_steps")
      .select("*", { count: "exact", head: true })
      .eq("run_id", runId)
      .eq("status", "pending");

    const durationMs = Date.now() - startedAt;

    return NextResponse.json(
      {
        success: true,
        runId,
        executedCount,
        executions,
        remainingPending,
        durationMs,
        message:
          remainingPending && remainingPending > 0
            ? "Executed up to limit; pending steps remain."
            : "All pending steps executed for this run."
      },
      { status: 200 }
    );
  } catch (err: any) {
    console.error("[/api/orchestrator/builder/execute-all] ERROR:", err);

    return NextResponse.json(
      {
        error: "BuilderExecuteAllError",
        message: err?.message ?? "Unknown error executing all builder steps.",
        stack:
          process.env.NODE_ENV !== "production"
            ? err?.stack ?? null
            : undefined
      },
      { status: 500 }
    );
  }
}
